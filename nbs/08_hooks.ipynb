{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hooks\n",
    "\n",
    "> Monitoring DL models statistics along the way ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# from copy import copy\n",
    "# import math\n",
    "# import fastcore.all as fc\n",
    "# from fastprogress import progress_bar, master_bar\n",
    "# from operator import attrgetter\n",
    "# from collections.abc import Mapping\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import torch\n",
    "# from torchvision import transforms as T\n",
    "# from torcheval.metrics import Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lssm.loading import load_ossl\n",
    "from lssm.models import conv\n",
    "from lssm.callbacks import to_cpu\n",
    "from lssm.preprocessing import Log1p, SNV\n",
    "from lssm.dataloaders import SpectralDataset, get_dls\n",
    "\n",
    "import torch\n",
    "from torch import nn, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading & selecting data ...\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "analytes = 'clay.tot_usda.a334_w.pct' # Let's play with Clay\n",
    "spectra_type = 'mir'\n",
    "\n",
    "data = load_ossl(analytes, spectra_type)\n",
    "X, y, X_names, smp_idx, ds_name, ds_label = data\n",
    "\n",
    "X = Pipeline([('snv', SNV())]).fit_transform(X)\n",
    "y = Log1p().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "# Train/valid split\n",
    "n_smp = None # For demo. purpose\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X[:n_smp, :], y[:n_smp],\n",
    "                                                      test_size=0.1,\n",
    "                                                      stratify=ds_name[:n_smp],\n",
    "                                                      random_state=41)\n",
    "\n",
    "# Get PyTorch datasets\n",
    "train_ds, valid_ds = [SpectralDataset(X, y, )\n",
    "                      for X, y, in [(X_train, y_train), (X_valid, y_valid)]]\n",
    "\n",
    "# Then PyTorch dataloaders\n",
    "dls = get_dls(train_ds, valid_ds, bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from functools import partial\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torcheval.metrics import R2Score\n",
    "from lssm.callbacks import (MetricsCB, BatchSchedCB, BatchTransformCB,\n",
    "                            DeviceCB, TrainCB, ProgressCB)\n",
    "from lssm.transforms import GADFTfm, _resizeTfm, StatsTfm\n",
    "from lssm.learner import Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ToyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            conv(1, 8, ks=5),        # 8, 851\n",
    "            conv(8, 16),             # 16, 426\n",
    "            conv(16, 32),            # 32, 213\n",
    "            conv(32, 64),            # 64, 107\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*107, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "epochs = 8\n",
    "lr = 1e-3\n",
    "\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "xtra = [BatchSchedCB(sched)]\n",
    "cbs = [DeviceCB(), TrainCB(), \n",
    "       MetricsCB(r2=R2Score()),\n",
    "       ProgressCB(plot=False)]\n",
    "\n",
    "learn = Learner(ToyCNN(), dls, nn.MSELoss(), lr=lr,\n",
    "                cbs=cbs+xtra, opt_func=optim.AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2        loss      epoch     train                                                         \n",
      "0.002     0.809     0         train     \n",
      "0.739     0.213     0         eval                                                      \n",
      "0.793     0.168     1         train                                                         \n",
      "0.746     0.207     1         eval                                                      \n",
      "0.825     0.142     2         train                                                         \n",
      "0.816     0.150     2         eval                                                      \n",
      "0.844     0.127     3         train                                                         \n",
      "0.851     0.121     3         eval                                                      \n",
      "0.855     0.117     4         train                                                         \n",
      "0.856     0.117     4         eval                                                      \n",
      "0.866     0.109     5         train                                                         \n",
      "0.864     0.111     5         eval                                                      \n",
      "0.873     0.103     6         train                                                         \n",
      "0.868     0.107     6         eval                                                      \n",
      "0.878     0.099     7         train                                                         \n",
      "0.870     0.106     7         eval                                                      \n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "learn.fit(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Hook():\n",
    "    def __init__(self, m, f): self.hook = m.register_forward_hook(partial(f, self))\n",
    "    def remove(self): self.hook.remove()\n",
    "    def __del__(self): self.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, epochs=1, xtra_cbs=None):\n",
    "    learn = Learner(model, dls, loss_func=F.cross_entropy, lr=0.6, cbs=cbs+fc.L(xtra_cbs))\n",
    "    learn.fit(epochs)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_stats(hook, mod, inp, outp):\n",
    "    if not hasattr(hook,'stats'): hook.stats = ([],[])\n",
    "    acts = to_cpu(outp)\n",
    "    hook.stats[0].append(acts.mean())\n",
    "    hook.stats[1].append(acts.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
