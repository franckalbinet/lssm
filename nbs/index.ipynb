{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Soil Spectral Models (LSSM)\n",
    "\n",
    "> Modelling pipeline to develop and monitor Large Soil Spectral Models (LSSM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Python package allowing to reproduce the research work done by [Franck Albinet](https://www.linkedin.com/in/franckalbinet) in the context of a PhD @ [KU Leuven](https://www.kuleuven.be/)  titled **\"Multiscale Characterization of Exchangeable Potassium Content in Soil to Remediate Agricultural Land Affected by Radioactive Contamination using Machine Learning, Soil Spectroscopy and Remote Sensing\"**. \n",
    "\n",
    "**Our first paper** [Albinet, F., Peng, Y., Eguchi, T., Smolders, E., Dercon, G., 2022. Prediction of exchangeable potassium in soil through mid-infrared spectroscopy and deep learning: From prediction to explainability. Artificial Intelligence in Agriculture 6, 230–241.](https://www.sciencedirect.com/science/article/pii/S2589721722000186) investigated the possibility to predict exchangeable potassium in soil using large Mid-infrared soil spectral libraries and Deep Learning. Code available [here](https://github.com/franckalbinet/mirzai).\n",
    "\n",
    "We are now **exploring the potential to characterize and predict exchangeable potassium using both Near- and Mid-infrared soil spectroscopy, with a focus on leveraging advanced Deep Learning models such as ResNet and ViT transformers through transfer learning**. \n",
    "\n",
    "*Our Deep Learning pipeline is primarily based on the approach described by [Jeremy Howard](https://github.com/fastai/course22p2)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install lssm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We demonstrate a typical workflow below to showcase our method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch import optim, nn\n",
    "\n",
    "import timm\n",
    "\n",
    "from torcheval.metrics import R2Score\n",
    "from torch.optim import lr_scheduler\n",
    "from lssm.loading import load_ossl\n",
    "from lssm.learner import Learner\n",
    "from lssm.preprocessing import ToAbsorbance, ContinuumRemoval, Log1p\n",
    "from lssm.dataloaders import SpectralDataset, get_dls\n",
    "from lssm.callbacks import (MetricsCB, BatchSchedCB, BatchTransformCB,\n",
    "                            DeviceCB, TrainCB, ProgressCB)\n",
    "from lssm.transforms import GADFTfm, _resizeTfm, StatsTfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training & validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load model from `timm` python package, Deep Learning State-Of-The-Art (SOTA) pre-trained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet18'\n",
    "model = timm.create_model(model_name, pretrained=True, in_chans=1, num_classes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Automatically download large spectral libraries developed by our colleagues at [WCRC](https://www.woodwellclimate.org). We focus on exchangeable potassium in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading & selecting data ...\n"
     ]
    }
   ],
   "source": [
    "analytes = 'k.ext_usda.a725_cmolc.kg'\n",
    "data = load_ossl(analytes, spectra_type='visnir')\n",
    "X, y, X_names, smp_idx, ds_name, ds_label = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. A bit of data features and target preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44489/44489 [00:15<00:00, 2850.84it/s]\n"
     ]
    }
   ],
   "source": [
    "X = Pipeline([('to_abs', ToAbsorbance()), \n",
    "              ('cr', ContinuumRemoval(X_names))]).fit_transform(X)\n",
    "\n",
    "y = Log1p().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Typical train/test split to get a train and valid dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_smp = 5000 # For demo. purpose (in reality we have > 50K)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X[:n_smp, :], y[:n_smp], \n",
    "                                                      test_size=0.1,\n",
    "                                                      stratify=ds_name[:n_smp], \n",
    "                                                      random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Finally, creating a custom PyTorch `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = [SpectralDataset(X, y, ) \n",
    "                      for X, y, in [(X_train, y_train), (X_valid, y_valid)]]\n",
    "\n",
    "# Then PyTorch dataloaders\n",
    "dls = get_dls(train_ds, valid_ds, bs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>r2</th>\n",
       "      <th>loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0.348</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0.545</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1\n",
    "lr = 5e-3\n",
    "\n",
    "# We use `r2` along to assess performance\n",
    "metrics = MetricsCB(r2=R2Score())\n",
    "\n",
    "# We use Once Cycle Learning Rate scheduling approach\n",
    "tmax = epochs * len(dls.train)\n",
    "sched = partial(lr_scheduler.OneCycleLR, max_lr=lr, total_steps=tmax)\n",
    "\n",
    "# A series of preprocessing performed on GPUs\n",
    "#    - put to GPU\n",
    "#    - transform to 1D to 2D spectra using Gramian Angular Difference Field (GADF)\n",
    "#    - resize the 2D version\n",
    "#    - apply pre-trained model stats\n",
    "xtra = [BatchSchedCB(sched)]\n",
    "gadf = BatchTransformCB(GADFTfm())\n",
    "resize = BatchTransformCB(_resizeTfm)\n",
    "stats = BatchTransformCB(StatsTfm(model.default_cfg))\n",
    "\n",
    "cbs = [DeviceCB(), gadf, resize, stats, TrainCB(), \n",
    "       metrics, ProgressCB(plot=False)]\n",
    "\n",
    "learn = Learner(model, dls, nn.MSELoss(), lr=lr, \n",
    "                cbs=cbs+xtra, opt_func=optim.AdamW)\n",
    "\n",
    "learn.fit(epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
